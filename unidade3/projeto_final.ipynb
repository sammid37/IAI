{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução à Inteligência Artificial\n",
    "\n",
    "**Unidade 3 - Projeto Final**\n",
    "\n",
    "Discente: Samnatha Dantas Medeiros\n",
    "\n",
    "> Dataset utilizado: https://www.kaggle.com/datasets/kevinzmith/honey-with-neonic-pesticide\n",
    "\n",
    "O estudo com este dataset visa analisar o impacto de pesticidas sobre colônias de abelha e assim prever o número de colônias nos próximos anos e como isso poderá impactar a vida.\n",
    "\n",
    "Todas as células de código encontram-se documentadas por células markdown e/ou possuem comentários sobre os métodos utilizados e sobre demais escolhas tomadas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambiente, funções e _misc_\n",
    "A seção a seguir contém a inicialização deste notebook (bibliotecas a serem utilizadas, funções de propósitos específicos e algumas variáveis para ficarem 'separadas' dos blocos adjacentes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependências\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, confusion_matrix, accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções\n",
    "# Funções de pré-processamento\n",
    "\n",
    "def all_unique_in(df):\n",
    "  '''\n",
    "  Busca por todos os valores únicos de um dataframe.\n",
    "\n",
    "  Args: o dataframe que se deseja extrair os valores únicos\n",
    "  Returns: a lista de valores únicos de cada coluna do dataframe\n",
    "  '''\n",
    "  pass\n",
    "\n",
    "def drop_cols(df, cols):\n",
    "  '''\n",
    "  Exclui a colunas indesejadas de um dataframe.\n",
    "  \n",
    "  Args: o dataframe e a lista de colunas do dataframe para remoção\n",
    "  Returns: o dataframe após a exclusão das coluna indesejadas\n",
    "  '''\n",
    "  pass\n",
    "\n",
    "def replace_with_median(df, n_cols, g_col):\n",
    "  '''\n",
    "  Substitui os valores ausentes de determinadas colunas agrupadas com a mediana (valores numéricos). Por exemplo, substitui valores ausentes de colônias pela mediana de acordo com o estado daquela colônia.\n",
    "  \n",
    "  Args: o dataframe, a lista de colunas do dataframe para tratamento e a coluna que irá agrupar os valores\n",
    "  Returns: o dataframe após o tratamento de valores ausentes das colunas\n",
    "  '''\n",
    "  pass\n",
    "\n",
    "def replace_with_mode(df, n_cols, g_col):\n",
    "  '''\n",
    "  Substitui os valores ausentes de determinadas colunas agrupadas com a moda (valores categóricos). Por exemplo, substitui valores ausentes de colônias pela mediana de acordo com o estado daquela colônia.\n",
    "  \n",
    "  Args: o dataframe, a lista de colunas do dataframe para tratamento e a coluna que irá agrupar os valores\n",
    "  Returns: o dataframe após o tratamento de valores ausentes das colunas\n",
    "  '''\n",
    "  pass\n",
    "\n",
    "# Funções para auxiliar nos algoritmos de aprendizado supervisionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializando os dataframes (um será o original, sem alterações e o outro será pré-processado e utilizado ao longo do desenvolvimento do projeto)\n",
    "og = pd.read_csv('./HoneyNeonic.csv', encoding='utf-8') # original\n",
    "df = pd.read_csv('./HoneyNeonic.csv', encoding='utf-8') # dataframe final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento\n",
    "O pré-processamento dos dados é uma etapa essencial para a construção de um modelo, pois utiliza diversas técnicas para melhorar a qualidade dos dados. \n",
    "\n",
    "**Sobre as colunas do _dataframe_**\n",
    "- *state* contém a sigla de um estado dos EUA\n",
    "- *numcol* representa o número de colônias produtoras de mel. \n",
    "  > Colônias produtoras de mel são o número máximo de colônias das quais o mel foi retirado durante o ano. É possível retirar mel de colônias que não sobreviveram durante todo o ano.\n",
    "- *yieldpercol* rendimento de mel por colônia (em libras)\n",
    "- *totalprod* produção total (`numcol x yieldpercol`) (em libras)\n",
    "- *stocks* estoques mantidos pelos produtores (em libras)\n",
    "- *priceperlb* preço médio por libra com base nas vendas ampliadas em dólares (US$)\n",
    "- *prodvalue* valor da produção (totalprod x priceperlb) em dólares (US$)\n",
    "- *year* ano de coleta dos dados\n",
    "- *StateName* contém o nome por extenso de um estado dos EUA\n",
    "- *Region* localização do estado no país (exemplo, o estado do Alabama é localizado no sudeste dos EUA)\n",
    "- *FIPS*\n",
    "  > FIPS é a sigla para \"Federal Information Processing Standards\" (Padrões Federais de Processamento de Informações, em tradução livre). O FIPS é um conjunto de padrões desenvolvido pelo Governo dos Estados Unidos para especificar requisitos para o processamento, armazenamento e transmissão de informações sensíveis e controladas pelo governo. No contexto específico de identificação geográfica, o FIPS é usado para se referir aos códigos FIPS (FIPS codes) que são atribuídos a várias entidades geográficas nos Estados Unidos. Esses códigos são usados para identificar estados, condados, cidades, distritos escolares e outras divisões administrativas dentro dos Estados Unidos. Eles fornecem um identificador único para cada entidade geográfica, facilitando o compartilhamento e a análise de dados relacionados a localizações específicas.\n",
    "- **Neonicidas**, as colunas a seguir representam a quantidade de neonicidas em kg para cada um deles\n",
    "  - *nCLOTHIANIDIN*\n",
    "  - *nIMIDACLOPRID*\n",
    "  - *nTHIAMETHOXAM*\n",
    "  - *nACETAMIPRID*\n",
    "  - *nTHIACLOPRID*\n",
    "  - *nAllNeonic* contém a quantidade total de neonicidas independente do tipo que seja\n",
    "\n",
    "\n",
    "### Colunas essenciais\n",
    "\n",
    "### Tratamento de valores ausentes\n",
    "\n",
    "### Outros processamentos de dados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state', 'numcol', 'yieldpercol', 'totalprod', 'stocks', 'priceperlb',\n",
       "       'prodvalue', 'year', 'StateName', 'Region', 'FIPS', 'nCLOTHIANIDIN',\n",
       "       'nIMIDACLOPRID', 'nTHIAMETHOXAM', 'nACETAMIPRID', 'nTHIACLOPRID',\n",
       "       'nAllNeonic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og.head()\n",
    "og.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
